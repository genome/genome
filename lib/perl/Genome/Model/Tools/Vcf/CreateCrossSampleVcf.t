#!/usr/bin/env genome-perl

use strict;
use warnings;

BEGIN {
    $ENV{UR_DBI_NO_COMMIT} = 1;
    $ENV{UR_USE_DUMMY_AUTOGENERATED_IDS} = 1;
    $ENV{NO_LSF} = 1;
};

use above "Genome";
use File::Temp;
use Test::More;
use Data::Dumper;
use File::Compare;

my $archos = `uname -a`;
if ($archos !~ /64/) {
    plan skip_all => "Must run from 64-bit machine";
}

my $cmd_class = 'Genome::Model::Tools::Vcf::CreateCrossSampleVcf';
my $sr_class = $cmd_class.'Result';

use_ok($cmd_class);
use_ok($sr_class);

my $joinx_version = "1.3";

my $refbuild_id = 101947881;
my $test_data_directory = $ENV{GENOME_TEST_INPUTS} . "/Genome-Model-Tools-Vcf-CreateCrossSampleVcf";
my $region_file = $test_data_directory."/input/feature_list_3.bed.gz";

my @input_builds = map{ Genome::Model::Build->get($_)} (116552788,116559016,116559101);

# Updated to .v2 for correcting an error with newlines
my $expected_directory = $test_data_directory . "/expected_4";
my $test_output_base = File::Temp::tempdir('Genome-Model-Tools-Vcf-CreateCrossSampleVcf-XXXXX', DIR => "$ENV{GENOME_TEST_TEMP}", CLEANUP => 1);

my %params_test1 = (
    output_directory => $test_output_base,
    builds => \@input_builds,
    max_files_per_merge => 2,
    variant_type => 'snvs',
    roi_file => $region_file,
    roi_name => "TEST_ROI_NAME",
    wingspan => 500,
    allow_multiple_processing_profiles => undef,
    joinx_version => $joinx_version,
);
my $ccsv_cmd = $cmd_class->create(%params_test1);

my $output_file = $test_output_base."/snvs.merged.vcf.gz";
my $expected_file = $expected_directory."/snvs.merged.vcf.gz";

ok($ccsv_cmd, "created CreateCrossSampleVcf object");
ok($ccsv_cmd->execute(), "executed CreateCrossSampleVcf");

delete $params_test1{'output_directory'};
my $software_result1 = $sr_class->get_with_lock(%params_test1);
ok($software_result1, "found software result for test1");
is($software_result1, $ccsv_cmd->software_result, 'found software result via cmd for test1');

# shouldn't be able to get the same software result as before with fewer inputs.
my %params_test_subset = %params_test1;
my @subset_input_builds = map{ Genome::Model::Build->get($_)} (116552788, 116559016);
$params_test_subset{"builds"} = \@subset_input_builds;
my $software_result_subset = $sr_class->get_with_lock(%params_test_subset);
ok(!defined($software_result_subset), "couldn't get software result with subset of (is_many) input.");

ok(-s $output_file, "executed output of CreateCrossSampleVcf, snvs.merged.vcf.gz exists");

#The files will have a timestamp that will differ. Ignore this but check the rest.
my $expected = `zcat $expected_file | grep -v fileDate`;
my $output = `zcat $output_file | grep -v fileDate`;

my $diff = Genome::Sys->diff_text_vs_text($output, $expected);
ok(!$diff, 'output matched expected result')
    or diag("diff results:\n" . $diff);

my $test_no_max_output_base = File::Temp::tempdir('Genome-Model-Tools-Vcf-CreateCrossSampleVcf-XXXXX', DIR => "$ENV{GENOME_TEST_TEMP}", CLEANUP => 1);

my %params_test2 = (
    output_directory => $test_no_max_output_base,
    builds => \@input_builds,
    max_files_per_merge => undef,
    variant_type => 'snvs',
    roi_file => $region_file,
    roi_name => "TEST_ROI_NAME",
    wingspan => 500,
    allow_multiple_processing_profiles => undef,
    joinx_version => $joinx_version,
);

my $ccsv_no_max_merge_cmd = $cmd_class->create(%params_test2);


my $no_max_output_file = $test_no_max_output_base."/snvs.merged.vcf.gz";

ok($ccsv_cmd, "created CreateCrossSampleVcf object");
ok($ccsv_no_max_merge_cmd->execute(), "executed CreateCrossSampleVcf");

delete $params_test2{'output_directory'};
my $software_result2 = $sr_class->get_with_lock(%params_test2);
ok($software_result2, "Found software result for test2");
is($software_result2, $ccsv_no_max_merge_cmd->software_result, 'Found software result via cmd for test2');

my $no_max_output = `zcat $output_file | grep -v fileDate`;

my $no_max_diff = Genome::Sys->diff_text_vs_text($no_max_output, $expected);
ok(!$no_max_diff, 'output matched expected result')
    or diag("diff results:\n" . $no_max_diff);

done_testing();
